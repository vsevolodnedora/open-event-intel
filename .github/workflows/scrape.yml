name: Scrape

on:
  push:
    branches: ["main"]
  schedule:
    - cron: '0 18 * * *'  # Runs at 18:00 UTC daily

jobs:
  update_data:
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule' || github.ref == 'refs/heads/main'
    permissions:
      contents: write
    env:
      LOG_LEVEL: WARNING
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11.5'
          cache: 'pipenv'

      - name: Install pipenv
        run: curl https://raw.githubusercontent.com/pypa/pipenv/master/get-pipenv.py | python

      - name: Install Dependencies
        run: pipenv install

      - name: Install Playwright Browsers
        run: pipenv run playwright install

      # Clone private data repo and pull existing DB
      - name: Clone Private Data Repo
        run: |
          git clone https://${{ secrets.NLP_NEWS_SUMMARY_DATA }}@github.com/vsevolodnedora/nlp_news_summary_data.git data_repo
          mkdir -p database
          cp data_repo/database/scraped_posts.db database/scraped_posts.db

      - name: Scrape Data
        run: pipenv run python run_scrape.py all

      # Copy updated DB back into private repo and push
      - name: Push Updated DB to Private Repo
        run: |
          cp database/scraped_posts.db data_repo/database/scraped_posts.db
          cd data_repo
          git config --global user.name 'Collector'
          git config --global user.email 'noreply@nedora.digital'
          git add database/scraped_posts.db
          git commit -m "Update scraped_posts.db from scraper run at $(date -u)"
          git push